# models/test_clip.py
# Test autonome du pipeline CLIP pour Vinted Lens

import torch
from transformers import CLIPProcessor, CLIPModel
import requests
from PIL import Image
from io import BytesIO
import numpy as np
import time
import sys
import os

def test_clip_pipeline():
    """Test complet du pipeline CLIP"""
    print("ğŸš€ Test CLIP Pipeline - Vinted Lens")
    print("=" * 50)
    
    # 1ï¸âƒ£ VÃ©rification environnement
    print(f"ğŸ Python: {sys.version}")
    print(f"ğŸ”¥ PyTorch: {torch.__version__}")
    print(f"ğŸ’» Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}")
    
    # 2ï¸âƒ£ Chargement du modÃ¨le CLIP
    print("\nğŸ“¥ Chargement CLIP model...")
    start_time = time.time()
    
    try:
        model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
        processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
        device = "cuda" if torch.cuda.is_available() else "cpu"
        model.to(device)
        
        load_time = time.time() - start_time
        print(f"âœ… ModÃ¨le chargÃ© en {load_time:.2f}s sur {device}")
        
    except Exception as e:
        print(f"âŒ Erreur chargement modÃ¨le: {e}")
        return False
    
    # 3ï¸âƒ£ Test avec image de vÃªtement rÃ©elle
    print("\nğŸ‘• Test encoding image de vÃªtement...")
    
    # Image test : T-shirt Unsplash (free)
    image_url = "https://images.unsplash.com/photo-1521572163474-6864f9cf17ab?w=400&h=400&fit=crop"
    
    try:
        # TÃ©lÃ©charger et traiter image
        print(f"ğŸ“¥ TÃ©lÃ©chargement: {image_url}")
        response = requests.get(image_url, timeout=15)
        response.raise_for_status()
        
        image = Image.open(BytesIO(response.content))
        print(f"ğŸ“¸ Image chargÃ©e: {image.size} ({image.mode})")
        
        # Encoder avec CLIP
        start_time = time.time()
        inputs = processor(images=image, return_tensors="pt").to(device)
        
        with torch.no_grad():
            image_features = model.get_image_features(**inputs)
            # Normalisation L2 pour similaritÃ© cosinus
            image_features = image_features / image_features.norm(dim=-1, keepdim=True)
        
        encode_time = time.time() - start_time
        embedding = image_features.cpu().numpy().flatten()
        
        print(f"âœ… Embedding gÃ©nÃ©rÃ© en {encode_time:.3f}s")
        print(f"âœ… Shape: {embedding.shape}")
        print(f"âœ… Dtype: {embedding.dtype}")
        print(f"âœ… Sample: [{embedding[0]:.4f}, {embedding[1]:.4f}, {embedding[2]:.4f}, ...]")
        print(f"âœ… Norm: {np.linalg.norm(embedding):.6f} (doit Ãªtre ~1.0)")
        
        # 4ï¸âƒ£ Test similaritÃ© (doit Ãªtre 1.0 avec elle-mÃªme)
        similarity = np.dot(embedding, embedding)
        print(f"âœ… Auto-similaritÃ©: {similarity:.6f} (parfait si ~1.0)")
        
        # 5ï¸âƒ£ Test avec texte (bonus)
        print("\nğŸ” Test embedding texte...")
        text_inputs = processor(text=["a red t-shirt", "blue jeans", "white sneakers"], 
                               return_tensors="pt", padding=True).to(device)
        
        with torch.no_grad():
            text_features = model.get_text_features(**text_inputs)
            text_features = text_features / text_features.norm(dim=-1, keepdim=True)
        
        # SimilaritÃ© image-texte
        text_similarities = []
        for i, text in enumerate(["red t-shirt", "blue jeans", "white sneakers"]):
            sim = np.dot(embedding, text_features[i].cpu().numpy())
            text_similarities.append((text, sim))
            print(f"ğŸ“ SimilaritÃ© '{text}': {sim:.4f}")
        
        print("\nğŸ‰ PIPELINE CLIP FONCTIONNEL - PRÃŠT POUR VINTED LENS!")
        print("=" * 50)
        
        return {
            'model_load_time': load_time,
            'encode_time': encode_time,
            'embedding_shape': embedding.shape,
            'embedding_norm': np.linalg.norm(embedding),
            'auto_similarity': similarity,
            'text_similarities': text_similarities,
            'device': device
        }
        
    except Exception as e:
        print(f"âŒ Erreur test: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("ğŸ¯ Test CLIP Pipeline - Vinted Lens")
    print("Assurez-vous d'Ãªtre dans le dossier backend avec l'env virtuel activÃ©")
    print()
    
    result = test_clip_pipeline()
    
    if result:
        print(f"\nğŸ“Š RÃ©sumÃ© Performance:")
        print(f"â€¢ Chargement modÃ¨le: {result['model_load_time']:.2f}s")
        print(f"â€¢ Encoding image: {result['encode_time']:.3f}s")
        print(f"â€¢ Device: {result['device']}")
        print(f"â€¢ PrÃªt pour intÃ©gration FastAPI! âœ…")
    else:
        print("\nâŒ Test Ã©chouÃ© - VÃ©rifiez les dÃ©pendances")
        sys.exit(1)